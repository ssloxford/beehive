{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "import tsfresh\n",
    "from datetime import timedelta\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from mlxtend.classifier import StackingCVClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from mlxtend.feature_selection import ColumnSelector\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from itertools import combinations\n",
    "from mlxtend.classifier import EnsembleVoteClassifier\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams.update({'font.size': 20})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sensor_types = ['mic', 'acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def featSelect(X, y):\n",
    "    return mutual_info_classif(X, y, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def trial_sample_extraction(path, disable_contact = False):\n",
    "    sensors_dict = {}\n",
    "    if disable_contact:\n",
    "        sensors = ['acc', 'mic']\n",
    "    else:\n",
    "        sensors = ['contact', 'acc', 'mic']\n",
    "    for sensor in sensors:\n",
    "        full_path = path + '_' + sensor + '.csv'\n",
    "        if not os.path.isfile(full_path):\n",
    "            return False\n",
    "        sample = pd.read_csv(full_path)\n",
    "        sample['time_s'] = sample['time_s'].apply(lambda epoch: epoch * 1e9)\n",
    "        sample['time_s'] = pd.to_datetime(sample['time_s'])\n",
    "        sample = sample.drop(sample.columns[0], axis=1)\n",
    "        sample.index = sample.time_s\n",
    "        sample = sample.drop(['time_s'], axis=1)\n",
    "        sensors_dict[sensor] = sample\n",
    "    return sensors_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def calc_jerk(acc_df):\n",
    "    date = pd.Series(acc_df.index)\n",
    "    date.index = pd.to_datetime(date)\n",
    "    time_d = (date - date.shift())\n",
    "    time_d = time_d.apply(lambda x: (x.microseconds/1000))\n",
    "\n",
    "    acc_df['jerk_x'] = acc_df['ax'].rolling(2).apply(lambda x: (x.iloc[1] - x.iloc[0]))\n",
    "    acc_df['jerk_x'] = acc_df['jerk_x'].div(time_d)\n",
    "\n",
    "    acc_df['jerk_y'] = acc_df['ay'].rolling(2).apply(lambda x: (x.iloc[1] - x.iloc[0]))\n",
    "    acc_df['jerk_y'] = acc_df['jerk_y'].div(time_d)\n",
    "\n",
    "    acc_df['jerk_z'] = acc_df['az'].rolling(2).apply(lambda x: (x.iloc[1] - x.iloc[0]))\n",
    "    acc_df['jerk_z'] = acc_df['jerk_z'].div(time_d)\n",
    "    acc_df.fillna(0, inplace=True)\n",
    "\n",
    "    return acc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def calc_stats(df):\n",
    "    stats_pd = pd.DataFrame()\n",
    "    for sensor_type in sensor_types:\n",
    "        for column in df[sensor_type].columns:\n",
    "            stats_pd['mean_' + column] = [df[sensor_type][column].mean()]\n",
    "            stats_pd['std_' + column] = [df[sensor_type][column].std()]\n",
    "            stats_pd['min_' + column] = [df[sensor_type][column].min()]\n",
    "            stats_pd['max_' + column] = [df[sensor_type][column].max()]\n",
    "            stats_pd['var_' + column] = [df[sensor_type][column].var()]\n",
    "            stats_pd['kurt_' + column] = [df[sensor_type][column].kurt()]\n",
    "            stats_pd['skew_' + column] = [df[sensor_type][column].skew()]\n",
    "            stats_pd['median_' + column] = [df[sensor_type][column].median()]\n",
    "            stats_pd['abs_energy_' + column] = [tsfresh.feature_extraction.feature_calculators.abs_energy(df[sensor_type][column])]\n",
    "            stats_pd['peaks_' + column] = [tsfresh.feature_extraction.feature_calculators.number_cwt_peaks(df[sensor_type][column], 2)]\n",
    "            stats_pd['derv_central_' + column] = [tsfresh.feature_extraction.feature_calculators.mean_second_derivative_central(df[sensor_type][column])]\n",
    "            stats_pd['mean_abs_change_' + column] = [tsfresh.feature_extraction.feature_calculators.mean_abs_change(df[sensor_type][column])]\n",
    "            stats_pd['abs_sum_change_' + column] = [tsfresh.feature_extraction.feature_calculators.absolute_sum_of_changes(df[sensor_type][column])]\n",
    "            stats_pd['fourier_entropy_' + column] = [tsfresh.feature_extraction.feature_calculators.fourier_entropy(df[sensor_type][column], 2)]\n",
    "            rms = np.sqrt(np.mean(df[sensor_type][column]**2))\n",
    "            stats_pd['root_mean_s_' + column] = [rms]\n",
    "            stats_pd['shape_factor_' + column] = [rms / (df[sensor_type][column].apply(abs).mean())]\n",
    "    stats_pd.reset_index(inplace=True, drop=True)\n",
    "    return stats_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def encodeLabels(df, binary, binary_target=None):\n",
    "    if binary:\n",
    "        df['label'] = np.where(df['label'].str.contains(binary_target), 1, 0)\n",
    "    else:\n",
    "        encoder = LabelEncoder()\n",
    "        df['label'] = encoder.fit_transform(df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def calcFeatureRelevance(df, binary):\n",
    "    class_num = df['label'].nunique()\n",
    "    X_f = df.drop('label', axis=1).astype(np.float64)\n",
    "    y_f = df['label']\n",
    "    df_relevant = tsfresh.feature_selection.relevance.calculate_relevance_table(X_f, y_f, 'classification', (not binary), class_num)\n",
    "    smallest_f = np.sort(df_relevant[df_relevant['relevant'] == True].index)\n",
    "    return smallest_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def gridSearchBest(model, param_grid, cv, X, y):\n",
    "    CV_rfc = GridSearchCV(estimator=model, param_grid=param_grid, cv=cv)\n",
    "    CV_rfc.fit(X, y)\n",
    "    return CV_rfc.best_estimator_, CV_rfc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def gridSearchSVMRF(sig_data, sig_data_attack_video, sig_data_attack_inperson, report_file, str_feat, sensor):\n",
    "    X_a_v = sig_data_attack_video.drop('label', axis=1)\n",
    "    y_a_v = sig_data_attack_video['label']\n",
    "\n",
    "    X_a_p = sig_data_attack_inperson.drop('label', axis=1)\n",
    "    y_a_p = sig_data_attack_inperson['label']\n",
    "\n",
    "    X = sig_data.drop('label', axis=1)\n",
    "    y = sig_data['label']\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    X_a_v = scaler.transform(X_a_v)\n",
    "    X_a_p = scaler.transform(X_a_p)\n",
    "\n",
    "    #RF\n",
    "\n",
    "    model = RandomForestClassifier()\n",
    "\n",
    "    param_grid = {\n",
    "        'n_estimators': [200, 500],\n",
    "        'max_features': ['auto', 'sqrt', 'log2'],\n",
    "        'max_depth' : [4,5,6,7,8],\n",
    "        'criterion' :['gini', 'entropy']\n",
    "    }\n",
    "\n",
    "    best_model, best_params = gridSearchBest(model, param_grid, cv, X, y)\n",
    "\n",
    "    print('Random Forest - Grid Search - tested on attacks - ' + str_feat, file = report_file)\n",
    "    print(\"Best params: \" + str(best_params), file = report_file)\n",
    "    best_model.fit(X, y)\n",
    "\n",
    "    rf_predictions_v = best_model.predict(X_a_v)\n",
    "    rf_predictions_p = best_model.predict(X_a_p)\n",
    "\n",
    "    print(confusion_matrix(y_a_v, rf_predictions_v), file = report_file)\n",
    "    print(classification_report(y_a_v, rf_predictions_v), file = report_file)\n",
    "    print(accuracy_score(y_a_v, rf_predictions_v), file = report_file)\n",
    "    rf_predictions_proba_v = best_model.predict_proba(X_a_v)\n",
    "    fpr, tpr, thresholds = roc_curve(y_a_v, rf_predictions_proba_v[:,1], pos_label=1)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    fig = plt.figure(figsize=(20,20))\n",
    "    plt.plot(fpr, tpr, lw=1, color='green', label=f'AUC = {roc_auc:.3f}')\n",
    "    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "    plt.title('ROC Curve for RF classifier - Video attacks')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate (Recall)')\n",
    "    plt.legend()\n",
    "    fig.savefig('./reports_per_device/ROC_RF_Video_' + sensor + \"_\" + str_feat + \".pdf\", format='pdf', dpi=600, bbox_inches = 'tight')\n",
    "\n",
    "    print(confusion_matrix(y_a_p, rf_predictions_p), file = report_file)\n",
    "    print(classification_report(y_a_p, rf_predictions_p), file = report_file)\n",
    "    print(accuracy_score(y_a_p, rf_predictions_p), file = report_file)\n",
    "    rf_predictions_proba_p = best_model.predict_proba(X_a_p)\n",
    "    fpr, tpr, thresholds = roc_curve(y_a_p, rf_predictions_proba_p[:,1], pos_label=1)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    fig = plt.figure(figsize=(20,20))\n",
    "    plt.plot(fpr, tpr, lw=1, color='green', label=f'AUC = {roc_auc:.3f}')\n",
    "    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "    plt.title('ROC Curve for RF classifier - In-person attacks')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate (Recall)')\n",
    "    plt.legend()\n",
    "    fig.savefig('./reports_per_device/ROC_RF_In-Person_' + sensor + \"_\" + str_feat + \".pdf\", format='pdf', dpi=600, bbox_inches = 'tight')\n",
    "\n",
    "    #SVM\n",
    "\n",
    "    model = SVC()\n",
    "    param_grid = {\n",
    "        'C': [0.1,1, 10, 100],\n",
    "        'gamma': [1,0.1,0.01,0.001],\n",
    "        'kernel': ['rbf', 'poly', 'sigmoid', 'linear']\n",
    "    }\n",
    "\n",
    "    best_model, best_params = gridSearchBest(model, param_grid, cv, X, y)\n",
    "\n",
    "    print('------------------', file = report_file)\n",
    "    print('SVM - Grid Search - tested on attacks - ' + str_feat, file = report_file)\n",
    "    print(\"Best params: \" + str(best_params), file = report_file)\n",
    "\n",
    "    best_model.fit(X, y)\n",
    "\n",
    "    svm_predictions_v = best_model.predict(X_a_v)\n",
    "    svm_predictions_p = best_model.predict(X_a_p)\n",
    "\n",
    "    print(confusion_matrix(y_a_v, svm_predictions_v), file = report_file)\n",
    "    print(classification_report(y_a_v, svm_predictions_v), file = report_file)\n",
    "    print(accuracy_score(y_a_v, svm_predictions_v), file = report_file)\n",
    "\n",
    "    clf = CalibratedClassifierCV(best_model) #to get probabilities from svm\n",
    "    clf.fit(X, y)\n",
    "\n",
    "    svm_predictions_proba_v = clf.predict_proba(X_a_v)\n",
    "    fpr, tpr, thresholds = roc_curve(y_a_v, svm_predictions_proba_v[:,1], pos_label=1)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    fig = plt.figure(figsize=(20,20))\n",
    "    plt.plot(fpr, tpr, lw=1, color='green', label=f'AUC = {roc_auc:.3f}')\n",
    "    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "    plt.title('ROC Curve for SVM classifier - Video attacks')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate (Recall)')\n",
    "    plt.legend()\n",
    "    fig.savefig('./reports_per_device/ROC_SVM_Video_' + sensor + \"_\" + str_feat + \".pdf\", format='pdf', dpi=600, bbox_inches = 'tight')\n",
    "\n",
    "    print(confusion_matrix(y_a_p, svm_predictions_p), file = report_file)\n",
    "    print(classification_report(y_a_p, svm_predictions_p), file = report_file)\n",
    "    print(accuracy_score(y_a_p, svm_predictions_p), file = report_file)\n",
    "\n",
    "    svm_predictions_proba_p = clf.predict_proba(X_a_p)\n",
    "    fpr, tpr, thresholds = roc_curve(y_a_p, svm_predictions_proba_p[:,1], pos_label=1)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    fig = plt.figure(figsize=(20,20))\n",
    "    plt.plot(fpr, tpr, lw=1, color='green', label=f'AUC = {roc_auc:.3f}')\n",
    "    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "    plt.title('ROC Curve for SVM classifier - In-person attacks')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate (Recall)')\n",
    "    plt.legend()\n",
    "    fig.savefig('./reports_per_device/ROC_SVM_In-person_' + sensor + \"_\" + str_feat + \".pdf\", format='pdf', dpi=600, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/w98_n4wj0x7cq61ljqncxjj80000gs/T/ipykernel_54547/3980674217.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['label'] = np.where(df['label'].str.contains(binary_target), 1, 0)\n"
     ]
    }
   ],
   "source": [
    "final_df = pd.DataFrame()\n",
    "final_df_attacks = pd.DataFrame()\n",
    "final_df_attacks_p = pd.DataFrame()\n",
    "final_first_pass = True\n",
    "\n",
    "set_sensors = ['O1', 'O2', 'O3', 'O4', 'O5', 'O6', 'O7', 'O8']\n",
    "\n",
    "video_ppl = ['pE', 'pA', 'pC', 'pG', 'pI', 'pL']\n",
    "\n",
    "for sensor in ['O1', 'O2', 'O3', 'O4', 'O5', 'O6', 'O7', 'O8']:\n",
    "\n",
    "    directory_in_str = './data_dev/' + sensor + '/day2/data/'\n",
    "    directory_in_str2 = './data_dev/' + sensor + '/day1/data/'\n",
    "\n",
    "    binary = True\n",
    "    s_f_num = 20\n",
    "    set_names = set()\n",
    "    set_paths = set()\n",
    "    first_pass = True\n",
    "    first_pass_attack = True\n",
    "    per_device_df = pd.DataFrame()\n",
    "    per_device_df_attack = pd.DataFrame()\n",
    "\n",
    "    directory = os.fsencode(directory_in_str)\n",
    "    for file in os.listdir(directory):\n",
    "        filename = os.fsdecode(file)\n",
    "        if filename.endswith(\".csv\"):\n",
    "            path = directory_in_str + filename\n",
    "            path = path[:-4]\n",
    "            path_elems = path.split(\"_\")\n",
    "            str_path = \"\"\n",
    "            str_path = str_path.join(\"_\".join(path_elems[:-1]))\n",
    "            set_paths.add(str_path)\n",
    "\n",
    "    directory = os.fsencode(directory_in_str2)\n",
    "    for file in os.listdir(directory):\n",
    "        filename = os.fsdecode(file)\n",
    "        if filename.endswith(\".csv\"):\n",
    "            if True:\n",
    "                path = directory_in_str2 + filename\n",
    "                path = path[:-4]\n",
    "                path_elems = path.split(\"_\")\n",
    "                str_path = \"\"\n",
    "                str_path = str_path.join(\"_\".join(path_elems[:-1]))\n",
    "                set_paths.add(str_path)\n",
    "\n",
    "    for path in sorted(set_paths):\n",
    "        if True:\n",
    "\n",
    "            #Extract the participant's name from the path\n",
    "            path_elems_global = path.split(\"/\")\n",
    "            path_elems_local = path_elems_global[-1].split(\"_\")\n",
    "            if len(path_elems_local) < 5:\n",
    "                continue\n",
    "            part_name = path_elems_local[1][0] + path_elems_local[2]\n",
    "            trial_stamp = path_elems_local[3] + \"_\" + path_elems_local[4]\n",
    "            set_names.add(part_name)\n",
    "\n",
    "            path_trial_part = \"_\".join(path_elems_local[1:])\n",
    "\n",
    "            #Extract the participant's trial from the sensor folder\n",
    "            sample1 = trial_sample_extraction(path)\n",
    "\n",
    "            if len(sample1['contact']) < 2:\n",
    "                continue\n",
    "\n",
    "            time_start = sample1['contact']['status'][sample1['contact']['status'] == 'open'].index[0]\n",
    "            time_stop = sample1['contact']['status'][sample1['contact']['status'] == 'close'].index[0]\n",
    "\n",
    "            #Extract the event from the sample - open and close the doors\n",
    "            for sensor_type in sensor_types:\n",
    "                t1 = (sample1[sensor_type].index >= (time_start - timedelta(seconds=1)))\n",
    "                t2 = (sample1[sensor_type].index <= (time_stop + timedelta(seconds=1)))\n",
    "                mask = t1 & t2\n",
    "                sample1[sensor_type] = sample1[sensor_type].loc[mask]\n",
    "\n",
    "            #Calc jerk\n",
    "            sample1['acc'] = calc_jerk(sample1['acc'])\n",
    "\n",
    "            #Calc features\n",
    "            sample1_stats = calc_stats(sample1)\n",
    "\n",
    "            first = True\n",
    "            #Extract paths from other devices based on the current trial and participant\n",
    "            for sens in set_sensors:\n",
    "                if sens not in [sensor]: #exclude the current device\n",
    "                    if \"contact\" not in path_trial_part:\n",
    "                        dir_ = './data_dev/' + sens + \"/\" + \"/\".join(path_elems_global[3:5]) + '/' + sens + \"_\" + path_trial_part\n",
    "                        sample_exter = trial_sample_extraction(dir_, True)\n",
    "\n",
    "                        if sample_exter == False:\n",
    "                            continue\n",
    "\n",
    "                        for sensor_type in sensor_types:\n",
    "                            t1 = (sample_exter[sensor_type].index >= (time_start - timedelta(seconds=1)))\n",
    "                            t2 = (sample_exter[sensor_type].index <= (time_stop + timedelta(seconds=1)))\n",
    "                            mask = t1 & t2\n",
    "                            sample_exter[sensor_type] = sample_exter[sensor_type].loc[mask]\n",
    "\n",
    "                        sample_exter['acc'] = calc_jerk(sample_exter['acc'])\n",
    "                        sample_exter_stats = calc_stats(sample_exter)\n",
    "                        sample_exter_stats.columns = [col + '_' + sens for col in sample_exter_stats.columns]\n",
    "\n",
    "                        if first:\n",
    "                            first = False\n",
    "                            per_colo_device_df = sample_exter_stats\n",
    "                        else:\n",
    "                            per_colo_device_df = pd.concat([per_colo_device_df, sample_exter_stats], axis=1)\n",
    "\n",
    "            #both main and colocated\n",
    "            helper_df = pd.concat([sample1_stats, per_colo_device_df], axis=1) #features from all the devices from the user's trial n authenticating interaction x\n",
    "\n",
    "            #only collocated\n",
    "            #helper_df = per_colo_device_df\n",
    "\n",
    "            #only main one\n",
    "            #helper_df = sample1_stats\n",
    "\n",
    "            helper_df['label'] = part_name\n",
    "            helper_df['trial_stamp'] = trial_stamp\n",
    "\n",
    "            if 'attack' in path:\n",
    "                if first_pass_attack:\n",
    "                    first_pass_attack = False\n",
    "                    per_device_df_attack = pd.DataFrame(columns=helper_df.columns)\n",
    "\n",
    "                per_device_df_attack = per_device_df_attack.append(helper_df, ignore_index = True)\n",
    "                continue\n",
    "\n",
    "            if first_pass:\n",
    "                first_pass = False\n",
    "                per_device_df = pd.DataFrame(columns=helper_df.columns)\n",
    "\n",
    "            per_device_df = per_device_df.append(helper_df, ignore_index = True)\n",
    "\n",
    "\n",
    "    per_device_df = per_device_df.dropna()\n",
    "    per_device_df.columns = [col + '_' + sensor if col not in ['label', 'trial_stamp'] else col for col in per_device_df.columns]\n",
    "    per_device_df_attack = per_device_df_attack.dropna()\n",
    "    per_device_df_attack.columns = [col + '_' + sensor if col not in ['label', 'trial_stamp'] else col for col in per_device_df_attack.columns]\n",
    "\n",
    "    if final_first_pass:\n",
    "        final_df = per_device_df\n",
    "        final_df_attacks = per_device_df_attack\n",
    "        final_first_pass = False\n",
    "        continue\n",
    "\n",
    "    final_df = pd.merge(final_df, per_device_df, on=['label', 'trial_stamp'])\n",
    "    final_df_attacks = pd.merge(final_df_attacks, per_device_df_attack, on=['label', 'trial_stamp'])\n",
    "\n",
    "final_df = final_df.drop('trial_stamp', axis=1)\n",
    "final_df_attacks = final_df_attacks.drop('trial_stamp', axis=1)\n",
    "\n",
    "df_final_attack_video = final_df_attacks[final_df_attacks['label'].str.contains('|'.join(video_ppl))]\n",
    "df_final_attack_inperson = final_df_attacks[~final_df_attacks['label'].str.contains('|'.join(video_ppl))]\n",
    "\n",
    "final_df_copy = final_df.copy() #storing original labels for zero-effort\n",
    "final_df_attacks_copy = final_df_attacks.copy() #storing original labels for attacks\n",
    "\n",
    "encodeLabels(final_df, binary, 'pF')\n",
    "encodeLabels(final_df_attacks, binary, 'pF')\n",
    "encodeLabels(df_final_attack_video, binary, 'pF')\n",
    "encodeLabels(df_final_attack_inperson, binary, 'pF')\n",
    "\n",
    "feat_set = {}\n",
    "\n",
    "t = 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for sensor in ['O1', 'O2', 'O3', 'O4', 'O5', 'O6', 'O7', 'O8']:\n",
    "    #Indexes of mutual inf\n",
    "    device_cols = [col for col in final_df.columns if sensor in col[-2:]]\n",
    "    X_c = final_df[device_cols]\n",
    "    y_c = final_df['label']\n",
    "\n",
    "    k = SelectKBest(featSelect, k=20).fit(X_c, y_c)\n",
    "    X_new = X_c.iloc[:, k.get_support(indices=True)]\n",
    "    feat_set[sensor] = X_new.columns\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, random_state=101, shuffle=True)\n",
    "sensors = ['O1', 'O2', 'O3', 'O4', 'O5', 'O6', 'O7', 'O8']\n",
    "\n",
    "estims = [\n",
    "('O1', make_pipeline(ColumnSelector(cols=feat_set[\"O1\"]), RandomForestClassifier(criterion= 'entropy', max_depth = 7, max_features = 'auto', n_estimators = 200))),\n",
    "('O2', make_pipeline(ColumnSelector(cols=feat_set[\"O2\"]), StandardScaler(), SVC(C = 100, gamma = 0.01, kernel = 'rbf', probability=True))),\n",
    "('O3', make_pipeline(ColumnSelector(cols=feat_set[\"O3\"]), RandomForestClassifier(criterion= 'gini', max_depth = 5, max_features = 'sqrt', n_estimators = 200))),\n",
    "('O4', make_pipeline(ColumnSelector(cols=feat_set[\"O4\"]), RandomForestClassifier(criterion= 'gini', max_depth = 5, max_features = 'sqrt', n_estimators = 200))),\n",
    "('O5', make_pipeline(ColumnSelector(cols=feat_set[\"O5\"]), RandomForestClassifier(criterion= 'entropy', max_depth = 7, max_features = 'sqrt', n_estimators = 200))),\n",
    "('O6', make_pipeline(ColumnSelector(cols=feat_set[\"O6\"]), RandomForestClassifier(criterion= 'gini', max_depth = 4, max_features = 'auto', n_estimators = 500))),\n",
    "('O7', make_pipeline(ColumnSelector(cols=feat_set[\"O7\"]), RandomForestClassifier(criterion= 'entropy', max_depth = 8, max_features = 'log2', n_estimators = 500))),\n",
    "('O8', make_pipeline(ColumnSelector(cols=feat_set[\"O8\"]), StandardScaler(), SVC(C = 1, gamma = 1, kernel = 'linear', probability=True)))]\n",
    "\n",
    "meta_class = LogisticRegression()\n",
    "\n",
    "comb_1 = combinations(sensors, 1)\n",
    "comb_2 = combinations(sensors, 2)\n",
    "comb_3 = combinations(sensors, 3)\n",
    "comb_4 = combinations(sensors, 4)\n",
    "comb_5 = combinations(sensors, 5)\n",
    "comb_6 = combinations(sensors, 6)\n",
    "comb_7 = combinations(sensors, 7)\n",
    "comb_8 = combinations(sensors, 8)\n",
    "\n",
    "X = final_df.drop('label', axis=1)\n",
    "y = final_df['label']\n",
    "\n",
    "#combins = [list(comb_2), list(comb_3), list(comb_4), list(comb_5), list(comb_6), list(comb_7), list(comb_8)]\n",
    "#combins = [list(comb_2), list(comb_3), list(comb_4)]\n",
    "combins = [list(comb_1)]\n",
    "\n",
    "#df_st_vo = pd.DataFrame(columns = [\"FAR_Base_S\", \"FAR_Base_V\", \"FAR_All_S\", \"FAR_All_V\", \"FAR_Vid_S\", \"FAR_Vid_V\", \"FAR_Per_S\", \"FAR_Per_V\"])\n",
    "df_s = pd.DataFrame(columns = [\"Zero_fpr\", \"Zero_tpr\", \"Video_fpr\", \"Video_tpr\", \"Person_fpr\", \"Person_tpr\"])\n",
    "df_v = pd.DataFrame(columns = [\"Zero_fpr\", \"Zero_tpr\", \"Video_fpr\", \"Video_tpr\", \"Person_fpr\", \"Person_tpr\"])\n",
    "\n",
    "i = 1\n",
    "\n",
    "ens_mean_frr_b_s = {}\n",
    "ens_mean_tpr_b_s = {}\n",
    "\n",
    "ens_mean_frr_b_v = {}\n",
    "ens_mean_tpr_b_v = {}\n",
    "\n",
    "ens_mean_frr_v_s = {}\n",
    "ens_mean_tpr_v_s = {}\n",
    "\n",
    "ens_mean_frr_v_v = {}\n",
    "ens_mean_tpr_v_v = {}\n",
    "\n",
    "ens_mean_frr_p_s = {}\n",
    "ens_mean_tpr_p_s = {}\n",
    "\n",
    "ens_mean_frr_p_v = {}\n",
    "ens_mean_tpr_p_v = {}\n",
    "\n",
    "#\n",
    "\n",
    "fold_frr_b_s = {}\n",
    "fold_tpr_b_s = {}\n",
    "\n",
    "fold_frr_b_v = {}\n",
    "fold_tpr_b_v = {}\n",
    "\n",
    "fold_frr_v_s = {}\n",
    "fold_tpr_v_s = {}\n",
    "\n",
    "fold_frr_v_v = {}\n",
    "fold_tpr_v_v = {}\n",
    "\n",
    "fold_frr_p_s = {}\n",
    "fold_tpr_p_s = {}\n",
    "\n",
    "fold_frr_p_v = {}\n",
    "fold_tpr_p_v = {}\n",
    "\n",
    "df_sum_st = pd.DataFrame(columns = [\"FAR_B\", \"FAR_V\", \"FAR_P\"])\n",
    "df_sum_vo = pd.DataFrame(columns = [\"FAR_B\", \"FAR_V\", \"FAR_P\"])\n",
    "first_fold = True\n",
    "ki = 0\n",
    "\n",
    "\n",
    "\n",
    "for train_index, test_index in cv.split(X, y):\n",
    "    tprs_b_s = []\n",
    "    frrs_b_s = []\n",
    "    aucs_b_s = []\n",
    "    mean_fpr_b_s = np.linspace(0, 1, 10000)\n",
    "\n",
    "    tprs_b_v = []\n",
    "    frrs_b_v = []\n",
    "    aucs_b_v = []\n",
    "    mean_fpr_b_v = np.linspace(0, 1, 10000)\n",
    "\n",
    "    tprs_v_s = []\n",
    "    frrs_v_s = []\n",
    "    aucs_v_s = []\n",
    "    mean_fpr_v_s = np.linspace(0, 1, 10000)\n",
    "\n",
    "    tprs_v_v = []\n",
    "    frrs_v_v = []\n",
    "    aucs_v_v = []\n",
    "    mean_fpr_v_v = np.linspace(0, 1, 10000)\n",
    "\n",
    "    tprs_p_s = []\n",
    "    frrs_p_s = []\n",
    "    aucs_p_s = []\n",
    "    mean_fpr_p_s = np.linspace(0, 1, 10000)\n",
    "\n",
    "    tprs_p_v = []\n",
    "    frrs_p_v = []\n",
    "    aucs_p_v = []\n",
    "    mean_fpr_p_v = np.linspace(0, 1, 10000)\n",
    "\n",
    "\n",
    "    df_bar_plot_stack = pd.DataFrame(columns = [\"FAR_B\", \"FAR_V\", \"FAR_P\"])\n",
    "    df_bar_plot_vote = pd.DataFrame(columns = [\"FAR_B\", \"FAR_V\", \"FAR_P\"])\n",
    "\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    counterr = 0\n",
    "\n",
    "    for comb_list in combins:\n",
    "        df_st = pd.DataFrame(columns = [\"FAR_B\", \"FAR_V\", \"FAR_P\"])\n",
    "        df_vo = pd.DataFrame(columns = [\"FAR_B\", \"FAR_V\", \"FAR_P\"])\n",
    "        for comb in comb_list:\n",
    "            active_estims = []\n",
    "            labels = []\n",
    "            for i in range(0, len(comb)):\n",
    "                ind = sensors.index(comb[i])\n",
    "                active_estims.append(estims[ind][1])\n",
    "                labels.append(estims[ind][0])\n",
    "\n",
    "            meta = StackingCVClassifier(classifiers = active_estims, meta_classifier = meta_class, cv=cv)\n",
    "            meta2 = EnsembleVoteClassifier(clfs = active_estims, voting='soft')\n",
    "\n",
    "            fit_model_stack = meta.fit(X_train, y_train)\n",
    "            fit_model_voting = meta2.fit(X_train, y_train)\n",
    "\n",
    "            #Baseline calcs\n",
    "            pred_st = fit_model_stack.predict_proba(X_test)\n",
    "\n",
    "            fpr_a_b_s, tpr_a_b_s, thresholds_a_b_s = roc_curve(y_test, pred_st[:, 1] , pos_label=1)\n",
    "            frr_a_b_s = [1-i for i in tpr_a_b_s]\n",
    "            roc_auc_a_b_s = auc(fpr_a_b_s, tpr_a_b_s)\n",
    "\n",
    "            interp_tpr = np.interp(mean_fpr_b_s, fpr_a_b_s, tpr_a_b_s)\n",
    "            interp_frr = np.interp(mean_fpr_b_s, fpr_a_b_s, frr_a_b_s)\n",
    "            interp_tpr[0] = 0.0\n",
    "            interp_frr[0] = 1\n",
    "            frrs_b_s.append(interp_frr)\n",
    "            tprs_b_s.append(interp_tpr)\n",
    "            aucs_b_s.append(roc_auc_a_b_s)\n",
    "            df_help = pd.DataFrame(columns=['fpr', 'tpr', 'tresh'])\n",
    "            df_help['fpr'] = fpr_a_b_s\n",
    "            df_help['tpr'] = tpr_a_b_s\n",
    "            df_help['tresh'] = thresholds_a_b_s\n",
    "            FAR_base_s = df_help[df_help['tpr'] == 1]['fpr'].min()\n",
    "\n",
    "            fpr_a_b_v, tpr_a_b_v, thresholds_a_b_v = roc_curve(y_test, fit_model_voting.predict_proba(X_test)[:,1], pos_label=1)\n",
    "            frr_a_b_v = [1-i for i in tpr_a_b_v]\n",
    "            roc_auc_a_b_v = auc(fpr_a_b_v, tpr_a_b_v)\n",
    "\n",
    "            interp_tpr = np.interp(mean_fpr_b_v, fpr_a_b_v, tpr_a_b_v)\n",
    "            interp_frr = np.interp(mean_fpr_b_v, fpr_a_b_v, frr_a_b_v)\n",
    "            interp_tpr[0] = 0.0\n",
    "            interp_frr[0] = 1\n",
    "            frrs_b_v.append(interp_frr)\n",
    "            tprs_b_v.append(interp_tpr)\n",
    "            aucs_b_v.append(roc_auc_a_b_v)\n",
    "            df_help = pd.DataFrame(columns=['fpr', 'tpr', 'tresh'])\n",
    "            df_help['fpr'] = fpr_a_b_v\n",
    "            df_help['tpr'] = tpr_a_b_v\n",
    "            df_help['tresh'] = thresholds_a_b_v\n",
    "            FAR_base_v = df_help[df_help['tpr'] == 1]['fpr'].min()\n",
    "\n",
    "            complete_df = pd.concat([X_test, y_test], axis = 1)\n",
    "            victim_test = complete_df[complete_df['label'] == 1]\n",
    "\n",
    "            con_tr_av = pd.concat([df_final_attack_video, victim_test], axis=0)\n",
    "            X_a_v = con_tr_av.drop('label', axis=1)\n",
    "            y_a_v = con_tr_av['label']\n",
    "\n",
    "            con_tr_ap = pd.concat([df_final_attack_inperson, victim_test], axis=0)\n",
    "            X_a_p = con_tr_ap.drop('label', axis=1)\n",
    "            y_a_p = con_tr_ap['label']\n",
    "\n",
    "            fpr_a_v_s, tpr_a_v_s, thresholds_a_v_s = roc_curve(y_a_v, fit_model_stack.predict_proba(X_a_v)[:, 1], pos_label=1)\n",
    "            frr_a_v_s = [1-i for i in tpr_a_v_s]\n",
    "            roc_auc_a_v_s = auc(fpr_a_v_s, tpr_a_v_s)\n",
    "\n",
    "            interp_tpr = np.interp(mean_fpr_v_s, fpr_a_v_s, tpr_a_v_s)\n",
    "            interp_frr = np.interp(mean_fpr_v_s, fpr_a_v_s, frr_a_v_s)\n",
    "            interp_tpr[0] = 0.0\n",
    "            interp_frr[0] = 1\n",
    "            tprs_v_s.append(interp_tpr)\n",
    "            frrs_v_s.append(interp_frr)\n",
    "            aucs_v_s.append(roc_auc_a_v_s)\n",
    "            df_help = pd.DataFrame(columns=['fpr', 'tpr', 'tresh'])\n",
    "            df_help['fpr'] = fpr_a_v_s\n",
    "            df_help['tpr'] = tpr_a_v_s\n",
    "            df_help['tresh'] = thresholds_a_v_s\n",
    "            FAR_av_s = df_help[df_help['tpr'] == 1]['fpr'].min()\n",
    "\n",
    "            fpr_a_v_v, tpr_a_v_v, thresholds_a_v_v = roc_curve(y_a_v, fit_model_voting.predict_proba(X_a_v)[:,1], pos_label=1)\n",
    "            frr_a_v_v = [1-i for i in tpr_a_v_v]\n",
    "            roc_auc_a_v_v = auc(fpr_a_v_v, tpr_a_v_v)\n",
    "\n",
    "            interp_tpr = np.interp(mean_fpr_v_v, fpr_a_v_v, tpr_a_v_v)\n",
    "            interp_frr = np.interp(mean_fpr_v_v, fpr_a_v_v, frr_a_v_v)\n",
    "            interp_tpr[0] = 0.0\n",
    "            interp_frr[0] = 1\n",
    "            tprs_v_v.append(interp_tpr)\n",
    "            frrs_v_v.append(interp_frr)\n",
    "            aucs_v_v.append(roc_auc_a_v_v)\n",
    "            df_help = pd.DataFrame(columns=['fpr', 'tpr', 'tresh'])\n",
    "            df_help['fpr'] = fpr_a_v_v\n",
    "            df_help['tpr'] = tpr_a_v_v\n",
    "            df_help['tresh'] = thresholds_a_v_v\n",
    "            FAR_av_v = df_help[df_help['tpr'] == 1]['fpr'].min()\n",
    "\n",
    "            fpr_a_p_s, tpr_a_p_s, thresholds_a_p_s = roc_curve(y_a_p, fit_model_stack.predict_proba(X_a_p)[:,1], pos_label=1)\n",
    "            frr_a_p_s = [1-i for i in tpr_a_p_s]\n",
    "            roc_auc_a_p_s = auc(fpr_a_p_s, tpr_a_p_s)\n",
    "\n",
    "            interp_tpr = np.interp(mean_fpr_p_s, fpr_a_p_s, tpr_a_p_s)\n",
    "            interp_frr = np.interp(mean_fpr_p_s, fpr_a_p_s, frr_a_p_s)\n",
    "            interp_tpr[0] = 0.0\n",
    "            interp_frr[0] = 1\n",
    "            tprs_p_s.append(interp_tpr)\n",
    "            frrs_p_s.append(interp_frr)\n",
    "            aucs_p_s.append(roc_auc_a_p_s)\n",
    "            df_help = pd.DataFrame(columns=['fpr', 'tpr', 'tresh'])\n",
    "            df_help['fpr'] = fpr_a_p_s\n",
    "            df_help['tpr'] = tpr_a_p_s\n",
    "            df_help['tresh'] = thresholds_a_p_s\n",
    "            FAR_ap_s = df_help[df_help['tpr'] == 1]['fpr'].min()\n",
    "\n",
    "            fpr_a_p_v, tpr_a_p_v, thresholds_a_p_v = roc_curve(y_a_p, fit_model_voting.predict_proba(X_a_p)[:,1], pos_label=1)\n",
    "            frr_a_p_v = [1-i for i in tpr_a_p_v]\n",
    "            roc_auc_a_p_v = auc(fpr_a_p_v, tpr_a_p_v)\n",
    "\n",
    "            interp_tpr = np.interp(mean_fpr_p_v, fpr_a_p_v, tpr_a_p_v)\n",
    "            interp_frr = np.interp(mean_fpr_p_v, fpr_a_p_v, frr_a_p_v)\n",
    "            interp_tpr[0] = 0.0\n",
    "            interp_frr[0] = 1\n",
    "            tprs_p_v.append(interp_tpr)\n",
    "            frrs_p_v.append(interp_frr)\n",
    "            aucs_p_v.append(roc_auc_a_p_v)\n",
    "            df_help = pd.DataFrame(columns=['fpr', 'tpr', 'tresh'])\n",
    "            df_help['fpr'] = fpr_a_p_v\n",
    "            df_help['tpr'] = tpr_a_p_v\n",
    "            df_help['tresh'] = thresholds_a_p_v\n",
    "            FAR_ap_v = df_help[df_help['tpr'] == 1]['fpr'].min()\n",
    "\n",
    "            df_st.loc[\"_\".join(labels)] = [FAR_base_s, FAR_av_s, FAR_ap_s]\n",
    "            df_vo.loc[\"_\".join(labels)] = [FAR_base_v,  FAR_av_v,  FAR_ap_v]\n",
    "\n",
    "        if len(comb) == 1:\n",
    "            ens = \"One device\"\n",
    "        if len(comb) == 2:\n",
    "            ens = \"Two devices\"\n",
    "        if len(comb) == 3:\n",
    "            ens = \"Three devices\"\n",
    "        if len(comb) == 4:\n",
    "            ens = \"Four devices\"\n",
    "        if len(comb) == 5:\n",
    "            ens = \"Five devices\"\n",
    "        if len(comb) == 6:\n",
    "            ens = \"Six devices\"\n",
    "        if len(comb) == 7:\n",
    "            ens = \"Seven devices\"\n",
    "        if len(comb) == 8:\n",
    "            ens = \"Eight devices\"\n",
    "\n",
    "        df_bar_plot_stack.loc[ens] = [df_st['FAR_B'].mean(), df_st['FAR_V'].mean(), df_st['FAR_P'].mean()]\n",
    "        df_bar_plot_vote.loc[ens] = [df_vo['FAR_B'].mean(), df_vo['FAR_V'].mean(), df_vo['FAR_P'].mean()]\n",
    "\n",
    "        ens_mean_frr_b_s[ens] = np.mean(frrs_b_s, axis=0)\n",
    "        ens_mean_tpr_b_s[ens] = np.mean(tprs_b_s, axis=0)\n",
    "\n",
    "        ens_mean_frr_b_v[ens] = np.mean(frrs_b_v, axis=0)\n",
    "        ens_mean_tpr_b_v[ens] = np.mean(tprs_b_v, axis=0)\n",
    "\n",
    "        ens_mean_frr_v_s[ens] = np.mean(frrs_v_s, axis=0)\n",
    "        ens_mean_tpr_v_s[ens] = np.mean(tprs_v_s, axis=0)\n",
    "\n",
    "        ens_mean_frr_v_v[ens] = np.mean(frrs_v_v, axis=0)\n",
    "        ens_mean_tpr_v_v[ens] = np.mean(tprs_v_v, axis=0)\n",
    "\n",
    "        ens_mean_frr_p_s[ens] = np.mean(frrs_p_s, axis=0)\n",
    "        ens_mean_tpr_p_s[ens] = np.mean(tprs_p_s, axis=0)\n",
    "\n",
    "        ens_mean_frr_p_v[ens] = np.mean(frrs_p_v, axis=0)\n",
    "        ens_mean_tpr_p_v[ens] = np.mean(tprs_p_v, axis=0)\n",
    "\n",
    "\n",
    "    ki = ki + 1\n",
    "    #print(\"Stacking\")\n",
    "    #print(df_bar_plot_stack)\n",
    "    #print(\"Voting\")\n",
    "    #print(df_bar_plot_vote)\n",
    "    if first_fold:\n",
    "        df_sum_st = df_bar_plot_stack.copy()\n",
    "        df_sum_vo = df_bar_plot_vote.copy()\n",
    "        first_fold = False\n",
    "        for i in [\"One device\"]:\n",
    "            fold_frr_b_s[i] = [ens_mean_frr_b_s[i]]\n",
    "            fold_tpr_b_s[i] = [ens_mean_tpr_b_s[i]]\n",
    "\n",
    "            fold_frr_b_v[i] = [ens_mean_frr_b_v[i]]\n",
    "            fold_tpr_b_v[i] = [ens_mean_tpr_b_v[i]]\n",
    "\n",
    "            fold_frr_v_s[i] = [ens_mean_frr_v_s[i]]\n",
    "            fold_tpr_v_s[i] = [ens_mean_tpr_v_s[i]]\n",
    "\n",
    "            fold_frr_v_v[i] = [ens_mean_frr_v_v[i]]\n",
    "            fold_tpr_v_v[i] = [ens_mean_tpr_v_v[i]]\n",
    "\n",
    "            fold_frr_p_s[i] = [ens_mean_frr_p_s[i]]\n",
    "            fold_tpr_p_s[i] = [ens_mean_tpr_p_s[i]]\n",
    "\n",
    "            fold_frr_p_v[i] = [ens_mean_frr_p_v[i]]\n",
    "            fold_tpr_p_v[i] = [ens_mean_frr_p_v[i]]\n",
    "    else:\n",
    "        df_sum_st = df_sum_st.add(df_bar_plot_stack)\n",
    "        #print(\"After Sum Stacking\")\n",
    "        #print(df_sum_st)\n",
    "        df_sum_vo = df_sum_vo.add(df_bar_plot_vote)\n",
    "        #print(\"After Sum Voting\")\n",
    "        #print(df_sum_vo)\n",
    "\n",
    "        #,\n",
    "        for i in [\"One device\"]:\n",
    "            fold_frr_b_s[i].append(ens_mean_frr_b_s[i])\n",
    "            fold_tpr_b_s[i].append(ens_mean_tpr_b_s[i])\n",
    "\n",
    "            fold_frr_b_v[i].append(ens_mean_frr_b_v[i])\n",
    "            fold_tpr_b_v[i].append(ens_mean_tpr_b_v[i])\n",
    "\n",
    "            fold_frr_v_s[i].append(ens_mean_frr_v_s[i])\n",
    "            fold_tpr_v_s[i].append(ens_mean_tpr_v_s[i])\n",
    "\n",
    "            fold_frr_v_v[i].append(ens_mean_frr_v_v[i])\n",
    "            fold_tpr_v_v[i].append(ens_mean_tpr_v_v[i])\n",
    "\n",
    "            fold_frr_p_s[i].append(ens_mean_frr_p_s[i])\n",
    "            fold_tpr_p_s[i].append(ens_mean_tpr_p_s[i])\n",
    "\n",
    "            fold_frr_p_v[i].append(ens_mean_frr_p_v[i])\n",
    "            fold_tpr_p_v[i].append(ens_mean_frr_p_v[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def calc_frrs(ens, _frrs_b_s, _tprs_b_s, _frrs_b_v, _tprs_b_v, _frrs_v_s, _tprs_v_s, _frrs_v_v, _tprs_v_v, _frrs_p_s, _tprs_p_s, _frrs_p_v, _tprs_p_v):\n",
    "\n",
    "    print(ens)\n",
    "\n",
    "    mean_frr_b_s = np.mean(_frrs_b_s, axis=0)\n",
    "    mean_frr_b_s[-1] = 0.0\n",
    "    mean_tpr_b_s = np.mean(_tprs_b_s, axis=0)\n",
    "    mean_tpr_b_s[-1] = 1.0\n",
    "\n",
    "    mean_frr_b_v = np.mean(_frrs_b_v, axis=0)\n",
    "    mean_frr_b_v[-1] = 0.0\n",
    "    mean_tpr_b_v = np.mean(_tprs_b_v, axis=0)\n",
    "    mean_tpr_b_v[-1] = 1.0\n",
    "\n",
    "    mean_frr_v_s = np.mean(_frrs_v_s, axis=0)\n",
    "    mean_frr_v_s[-1] = 0.0\n",
    "    mean_tpr_v_s = np.mean(_tprs_v_s, axis=0)\n",
    "    mean_tpr_v_s[-1] = 1.0\n",
    "\n",
    "    mean_frr_v_v = np.mean(_frrs_v_v, axis=0)\n",
    "    mean_frr_v_v[-1] = 0.0\n",
    "    mean_tpr_v_v = np.mean(_tprs_v_v, axis=0)\n",
    "    mean_tpr_v_v[-1] = 1.0\n",
    "\n",
    "    mean_frr_p_s = np.mean(_frrs_p_s, axis=0)\n",
    "    mean_frr_p_s[-1] = 0.0\n",
    "    mean_tpr_p_s = np.mean(_tprs_p_s, axis=0)\n",
    "    mean_tpr_p_s[-1] = 1.0\n",
    "\n",
    "    mean_frr_p_v = np.mean(_frrs_p_v, axis=0)\n",
    "    mean_frr_p_v[-1] = 0.0\n",
    "    mean_tpr_p_v = np.mean(_tprs_p_v, axis=0)\n",
    "    mean_tpr_p_v[-1] = 1.0\n",
    "\n",
    "\n",
    "    #Zero-effort\n",
    "\n",
    "    print(\"Mean frr baseline (Stacking):\")\n",
    "    df_help = pd.DataFrame(columns=['fpr', 'frr'])\n",
    "    df_help['fpr'] = mean_fpr_b_s\n",
    "    df_help['frr'] = mean_frr_b_s\n",
    "    FAR_at_01_b_s = df_help[round(df_help['fpr'],4) == 0.1000]['frr'].min()\n",
    "    print(\"FAR 0.1: \" + str(round(FAR_at_01_b_s,4)))\n",
    "    FAR_at_001_b_s = df_help[round(df_help['fpr'],4) == 0.0100]['frr'].min()\n",
    "    print(\"FAR 0.01: \" + str(round(FAR_at_001_b_s,4)))\n",
    "    FAR_at_0001 = df_help[round(df_help['fpr'],4) == 0.0010]['frr'].min()\n",
    "    print(\"FAR 0.001: \" + str(round(FAR_at_0001,4)))\n",
    "    FAR_at_00001 = df_help[round(df_help['fpr'],4) == 0.0001]['frr'].min()\n",
    "    print(\"FAR 0.0001: \" + str(round(FAR_at_00001, 4)))\n",
    "\n",
    "\n",
    "    print(\"Mean frr baseline (Voting):\")\n",
    "    df_help = pd.DataFrame(columns=['fpr', 'frr'])\n",
    "    df_help['fpr'] = mean_fpr_b_v\n",
    "    df_help['frr'] = mean_frr_b_v\n",
    "    FAR_at_01_b_v = df_help[round(df_help['fpr'],4) == 0.1000]['frr'].min()\n",
    "    print(\"FAR 0.1: \" + str(round(FAR_at_01_b_v,4)))\n",
    "    FAR_at_001_b_v = df_help[round(df_help['fpr'],4) == 0.0100]['frr'].min()\n",
    "    print(\"FAR 0.01: \" + str(round(FAR_at_001_b_v,4)))\n",
    "    FAR_at_0001 = df_help[round(df_help['fpr'],4) == 0.0010]['frr'].min()\n",
    "    print(\"FAR 0.001: \" + str(round(FAR_at_0001,4)))\n",
    "    FAR_at_00001 = df_help[round(df_help['fpr'],4) == 0.0001]['frr'].min()\n",
    "    print(\"FAR 0.0001: \" + str(round(FAR_at_00001, 4)))\n",
    "\n",
    "    #Video\n",
    "\n",
    "    print(\"Mean frr video (Stacking):\")\n",
    "    df_help = pd.DataFrame(columns=['fpr', 'frr'])\n",
    "    df_help['fpr'] = mean_fpr_v_s\n",
    "    df_help['frr'] = mean_frr_v_s\n",
    "    FAR_at_01_v_s = df_help[round(df_help['fpr'],4) == 0.1000]['frr'].min()\n",
    "    print(\"FAR 0.1: \" + str(round(FAR_at_01_v_s, 4)))\n",
    "    FAR_at_001_v_s = df_help[round(df_help['fpr'],4) == 0.0100]['frr'].min()\n",
    "    print(\"FAR 0.01: \" + str(round(FAR_at_001_v_s, 4)))\n",
    "    FAR_at_0001 = df_help[round(df_help['fpr'],4) == 0.0010]['frr'].min()\n",
    "    print(\"FAR 0.001: \" + str(round(FAR_at_0001,4)))\n",
    "    FAR_at_00001 = df_help[round(df_help['fpr'],4) == 0.0001]['frr'].min()\n",
    "    print(\"FAR 0.0001: \" + str(round(FAR_at_00001, 4)))\n",
    "\n",
    "    print(\"Mean frr video (Voting):\")\n",
    "    df_help = pd.DataFrame(columns=['fpr', 'frr'])\n",
    "    df_help['fpr'] = mean_fpr_v_v\n",
    "    df_help['frr'] = mean_frr_v_v\n",
    "    FAR_at_01_v_v = df_help[round(df_help['fpr'],4) == 0.1000]['frr'].min()\n",
    "    print(\"FAR 0.1: \" + str(round(FAR_at_01_v_v, 4)))\n",
    "    FAR_at_001_v_v = df_help[round(df_help['fpr'],4) == 0.0100]['frr'].min()\n",
    "    print(\"FAR 0.01: \" + str(round(FAR_at_001_v_v, 4)))\n",
    "    FAR_at_0001 = df_help[round(df_help['fpr'],4) == 0.0010]['frr'].min()\n",
    "    print(\"FAR 0.001: \" + str(round(FAR_at_0001,4)))\n",
    "    FAR_at_00001 = df_help[round(df_help['fpr'],4) == 0.0001]['frr'].min()\n",
    "    print(\"FAR 0.0001: \" + str(round(FAR_at_00001, 4)))\n",
    "\n",
    "    #In-person\n",
    "\n",
    "    print(\"Mean frr in-person (Stacking):\")\n",
    "    df_help = pd.DataFrame(columns=['fpr', 'frr'])\n",
    "    df_help['fpr'] = mean_fpr_p_s\n",
    "    df_help['frr'] = mean_frr_p_s\n",
    "    FAR_at_01_p_s = df_help[round(df_help['fpr'],4) == 0.1000]['frr'].min()\n",
    "    print(\"FAR 0.1: \" + str(round(FAR_at_01_p_s, 4)))\n",
    "    FAR_at_001_p_s = df_help[round(df_help['fpr'],4) == 0.0100]['frr'].min()\n",
    "    print(\"FAR 0.01: \" + str(round(FAR_at_001_p_s, 4)))\n",
    "    FAR_at_0001 = df_help[round(df_help['fpr'],4) == 0.0010]['frr'].min()\n",
    "    print(\"FAR 0.001: \" + str(round(FAR_at_0001,4)))\n",
    "    FAR_at_00001 = df_help[round(df_help['fpr'],4) == 0.0001]['frr'].min()\n",
    "    print(\"FAR 0.0001: \" + str(round(FAR_at_00001, 4)))\n",
    "\n",
    "    print(\"Mean frr in-person (Voting):\")\n",
    "    df_help = pd.DataFrame(columns=['fpr', 'frr'])\n",
    "    df_help['fpr'] = mean_fpr_p_v\n",
    "    df_help['frr'] = mean_frr_p_v\n",
    "    FAR_at_01_p_v = df_help[round(df_help['fpr'],4) == 0.1000]['frr'].min()\n",
    "    print(\"FAR 0.1: \" + str(round(FAR_at_01_p_v, 4)))\n",
    "    FAR_at_001_p_v = df_help[round(df_help['fpr'],4) == 0.0100]['frr'].min()\n",
    "    print(\"FAR 0.01: \" + str(round(FAR_at_001_p_v, 4)))\n",
    "    FAR_at_0001 = df_help[round(df_help['fpr'],4) == 0.0010]['frr'].min()\n",
    "    print(\"FAR 0.001: \" + str(round(FAR_at_0001,4)))\n",
    "    FAR_at_00001 = df_help[round(df_help['fpr'],4) == 0.0001]['frr'].min()\n",
    "    print(\"FAR 0.0001: \" + str(round(FAR_at_00001, 4)))\n",
    "\n",
    "    #return [FAR_at_01_b_s, FAR_at_001_b_s, FAR_at_01_b_v, FAR_at_001_b_v, FAR_at_01_v_s, FAR_at_001_v_s, FAR_at_01_v_v, FAR_at_001_v_v, FAR_at_01_p_s, FAR_at_001_p_s, FAR_at_01_p_v, FAR_at_001_p_v]\n",
    "    return [FAR_at_01_b_v, FAR_at_001_b_v, FAR_at_01_v_v, FAR_at_001_v_v, FAR_at_01_p_v, FAR_at_001_p_v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One device\n",
      "Mean frr baseline (Stacking):\n",
      "FAR 0.1: 0.0619\n",
      "FAR 0.01: 0.0681\n",
      "FAR 0.001: 0.0687\n",
      "FAR 0.0001: 0.0687\n",
      "Mean frr baseline (Voting):\n",
      "FAR 0.1: 0.025\n",
      "FAR 0.01: 0.025\n",
      "FAR 0.001: 0.025\n",
      "FAR 0.0001: 0.025\n",
      "Mean frr video (Stacking):\n",
      "FAR 0.1: 0.4452\n",
      "FAR 0.01: 0.8192\n",
      "FAR 0.001: 0.8863\n",
      "FAR 0.0001: 0.893\n",
      "Mean frr video (Voting):\n",
      "FAR 0.1: 0.2125\n",
      "FAR 0.01: 0.2375\n",
      "FAR 0.001: 0.2375\n",
      "FAR 0.0001: 0.2375\n",
      "Mean frr in-person (Stacking):\n",
      "FAR 0.1: 0.163\n",
      "FAR 0.01: 0.4356\n",
      "FAR 0.001: 0.5161\n",
      "FAR 0.0001: 0.5241\n",
      "Mean frr in-person (Voting):\n",
      "FAR 0.1: 0.1688\n",
      "FAR 0.01: 0.2625\n",
      "FAR 0.001: 0.2625\n",
      "FAR 0.0001: 0.2625\n"
     ]
    }
   ],
   "source": [
    "df_frrs_ens = pd.DataFrame(columns = [\"Zero-effort (FAR = 0.1)\", \"Zero-effort (FAR = 0.01)\",\n",
    "                                      \"Video (FAR = 0.1)\", \"Video (FAR = 0.01)\",\n",
    "                                      \"In-Person (FAR = 0.1)\", \"In-Person (FAR = 0.01)\"])\n",
    "\n",
    "for i in [\"One device\"]:\n",
    "    df_frrs_ens.loc[i] = calc_frrs(i, fold_frr_b_s[i], fold_tpr_b_s[i], fold_frr_b_v[i], fold_tpr_b_v[i],\n",
    "                                   fold_frr_v_s[i], fold_tpr_v_s[i], fold_frr_v_v[i], fold_tpr_v_v[i],\n",
    "                                   fold_frr_p_s[i], fold_tpr_p_s[i], fold_frr_p_v[i], fold_tpr_p_v[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ DF combined -----\n",
      "Zero-effort (FAR = 0.1)     0.02500\n",
      "Zero-effort (FAR = 0.01)    0.02500\n",
      "Video (FAR = 0.1)           0.21250\n",
      "Video (FAR = 0.01)          0.23750\n",
      "In-Person (FAR = 0.1)       0.16875\n",
      "In-Person (FAR = 0.01)      0.26250\n",
      "Name: One device, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"------ DF combined -----\")\n",
    "print(df_frrs_ens.loc['One device'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
